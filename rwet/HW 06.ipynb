{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac1f659",
   "metadata": {},
   "source": [
    "# Homework 06 - The Final \n",
    "\n",
    "Updating the work from Hw5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716a840",
   "metadata": {},
   "source": [
    "---\n",
    "# Loading transformers\n",
    "Just doing the basics. Copied from Homework 05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8dbd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b2e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb86503",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4cae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiachang/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/leiachang/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once, I started to walk around the city to see if this was what you wanted. I started to walk around the city to see if this was what you wanted. I started to walk around the city to see if this was what you wanted.\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"Once, I started to walk\")[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a37bd8",
   "metadata": {},
   "source": [
    "---\n",
    "# Fine Tuning with Peter Pan \n",
    "I think I want to fine-tune this model to fit something a little closer to home. I have a deep love for Peter Pan, so I downloaded the text from Project Gutenberg to work with. Peter Pan (as troublesome as some of the story is) holds themes of everlasting childhood, love for wonder, and imagination. \n",
    "\n",
    "File sources are: \n",
    "```\n",
    "\"sources/peter-pan.txt\"\n",
    "```\n",
    "\n",
    "At first I created a truncated text to work with (seen in the cell below), but I realized that the majority of the more interesting, descriptive language occurs later in the text. I decided to try to train using the full text instead, which definitely took longer, but still only about 4 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ccc393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a truncated peter-pan text to work with\n",
    "with open(\"sources/truncated-peter-pan.txt\", \"w\") as fh:\n",
    "    fh.write(open(\"sources/peter-pan.txt\").read()[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8a4542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: responses<0.19 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: multiprocess in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: xxhash in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: packaging in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: filelock in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leiachang/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f806b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e300b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/Users/leiachang/.cache/huggingface/datasets/text/default-33e0c349e4d6c2f1/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac4031b766f4e239eb280a986d69aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = datasets.load_dataset('text', data_files=\"sources/peter-pan.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a659267b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_training_data = training_data.map(\n",
    "    lambda x: tokenizer(x['text']),\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be870bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = 64\n",
    "# magic from https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "lm_training_data = tokenized_training_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9244ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e2c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  train_dataset=lm_training_data['train'],\n",
    "                  args=TrainingArguments(\n",
    "                      output_dir='distilgpt2-finetune-peter-pan',\n",
    "                      num_train_epochs=1,\n",
    "                      do_train=True,\n",
    "                      do_eval=False\n",
    "                  ),\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e454bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiachang/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 03:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=129, training_loss=4.0501832000969, metrics={'train_runtime': 184.2312, 'train_samples_per_second': 5.602, 'train_steps_per_second': 0.7, 'total_flos': 16853640413184.0, 'train_loss': 4.0501832000969, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d45ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb084a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"It's time to rest.         It is the last time that anyone is ever gone and never has been there. I hope you will.”“““”“”“Not really,”“”” said St. John. “I wish you could go back, but I say a little more.”“No,” said Mrs.“Yes, no.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"It's time to rest.  \", max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267a977",
   "metadata": {},
   "source": [
    "---\n",
    "# Using the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd2d4c",
   "metadata": {},
   "source": [
    "For this iteration, I'm still looking at how I might sift a narrative out of a set of generated texts, each getting more and more randomized/unlikely. My idea is to find a narrative of escape, playing into the themes within Peter Pan of escapism, exploration, and drama. After my experiments the other week, I decided that I wanted to take a heavier hand at editing the output text. \n",
    "\n",
    "Below, I generate 5 samples each of a particular temperature and top_k. For each set, I either increase temperature, or the size of the top_k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd1a6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I am running away. I am running away, and \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22091348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_t_1 = []\n",
    "\n",
    "for x in range(5): \n",
    "    generated_t_1.append(generator(prompt, temperature = 1.0, max_length = 50)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca758ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_t_2 = []\n",
    "\n",
    "for x in range(5): \n",
    "    generated_t_2.append(generator(prompt, temperature = 2.0, max_length = 50)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "067d19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_k_100 = []\n",
    "\n",
    "for x in range(5): \n",
    "    generated_k_100.append(generator(prompt, top_k = 100, temperature = 2.0, max_length = 50)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f6e5522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_k_500 = []\n",
    "\n",
    "for x in range(5): \n",
    "    generated_k_500.append(generator(prompt, top_k = 500, temperature = 2.0, max_length = 50)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3ad2e",
   "metadata": {},
   "source": [
    "--- \n",
    "# Adding Formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c45e64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e13b8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_inserted = [\"\\n\", \"          \", \"\\n\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfff9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(text): \n",
    "    words = text.split()\n",
    "    maxIndex = len(words)\n",
    "    chosenIndexes = random.sample(range(0, maxIndex), 5)\n",
    "    for i in chosenIndexes: \n",
    "        words.insert(i, random.choice(to_be_inserted))\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5b83fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am running away. I \n",
      " am \n",
      " running away, \n",
      " and !!!” I have come from the last night. “To the rescue?” I am still a \n",
      " long time away!I am not the only one \n",
      " who are looking for me\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "\n",
      "\n",
      " I am running away. I            am running away, and --------------!”“Mothers,” I said, “I do not want \n",
      "\n",
      " \n",
      "\n",
      " you to \n",
      "\n",
      " be happy.”“I am, Mr. Brien.�\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "           I am running away. I am running away, and \n",
      " iphante!”He’s trying to think of \n",
      "\n",
      " a dead            man, but to say it is a lie.The wind was very            heavy with them, but they seemed to\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am \n",
      "\n",
      " running            away. I am \n",
      " running away, and                       HAPPY, SISTER.”“Laughter” he cried and asked “Why?”“What did you do?” said the captain\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I            am \n",
      "\n",
      " running away. I am running away, and ’Oh my, my sweet \n",
      "\n",
      " bird.”“Now,” he            said, “I can save my life, and \n",
      " by going.”“I am\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in generated_t_1: \n",
    "    print(add_spaces(text))\n",
    "    print(\"\\n\\n -------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9879d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am \n",
      " running away. \n",
      " I am running away, and _________________Peter - My            wife is quite close at arm in arm but alittle bird \n",
      "\n",
      " by arm by foot in foot. Now for Peter’’s mother Mrs. Jane \n",
      " and Mrs\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I am \n",
      " running away, and the path there in it!“You can find            one or we all here \n",
      "\n",
      " by walking            us here?“He says \n",
      " the stairs that should look more for your house. His home\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I am running away, \n",
      " and ************************The music, from it is that song which lives me!Tiffler \n",
      "\n",
      " has \n",
      " now \n",
      "\n",
      " won!Wendy goes. He knows ofthe boy. \n",
      "\n",
      " She doesle with me.\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I am running away, and ickles \n",
      "\n",
      " on fire. So on his \n",
      "\n",
      " \n",
      "\n",
      " way into an ambush...not just for his \n",
      " escape- but now more. Now \n",
      "\n",
      " and they look as he goes after a moment when she stops. What\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am \n",
      "\n",
      " running \n",
      " away. I am running away, and ___________|the ship wouldnot do \n",
      " her a man‏, she says, pointing to            the \n",
      "\n",
      " youngsore, ’and thereis nothing I could see about an Island, without\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in generated_t_2: \n",
    "    print(add_spaces(text))\n",
    "    print(\"\\n\\n -------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9844f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am running away. I am running away, and ________For you boys they            tell Wendy.The door is blown by day.Then \n",
      " their mouth must \n",
      " have drifted off:In \n",
      "\n",
      " this they will \n",
      " keep growing till Peter was as redinned withf\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I am running away, and ickling in amazement, his mouth open saying            so slowly!That is every small animal in his little short \n",
      " space who once in the world hewaswitching his            love? \n",
      " \n",
      "\n",
      " But his very\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running \n",
      "\n",
      " away. I \n",
      "            am running away, and ................................ the moment he arrived on that trail; which in one short moment is that time was on his clock if what \n",
      "\n",
      " was \n",
      " the way was found just before. To this time at last there\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am \n",
      "\n",
      " running away. I am running away, and *************That’s something \n",
      " I’charmed \n",
      "\n",
      " most \n",
      "\n",
      " nights while in the wilderness until            she found the strange spot that shewed round him.\"Dakkamus, not an\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I am running \n",
      " away, and ____had shebeen frightened now? Oh.”Oh dear, he            \n",
      "\n",
      " could always think \n",
      " forthought for which She \n",
      "\n",
      " passed� visas.But there were other visitors butthere.And that happened\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in generated_k_100: \n",
    "    print(add_spaces(text))\n",
    "    print(\"\\n\\n -------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc92c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am running away. I am \n",
      " running away, and ! That \n",
      "\n",
      " is good still: many or \n",
      "\n",
      " \n",
      " from the balcony, next Monday, it hardly may grow rich; but keep trying to pull \n",
      "\n",
      " apart first for whereletfor to kiss It then\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I \n",
      "\n",
      " am running away, and ....................... as \n",
      "\n",
      " Dinkhouse wou had said            Wier now --suddenlyB and they shall pass Jane \n",
      " has hurried home            by-- under his powerDylan‡baring him;gone\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I \n",
      " am running away. I am \n",
      " running away, and ****************I WANT TER’ with \n",
      " ALLERSON who let Sarah \n",
      " keep, and amforth upon \n",
      "\n",
      " her hat leaves besidegably my side;what remain amoved this parting of story at it length\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. \n",
      "\n",
      " I am running \n",
      "\n",
      " away, \n",
      " and Hook began!Father what dair answered quite alarm by once weft forward for much the long the nade waitagrosethere put            where Hoomin should've            taught, himselfflating\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      "I am running away. I am running away, and ~~ o of, \n",
      "\n",
      " was watching him cheering me with            love.Would that fright \n",
      " broke easilyie \n",
      " quiet but let Tika run afterwards carrying?was the three eldest citizens            all feeling grief slowlyonme\n",
      "\n",
      "\n",
      " -------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in generated_k_500: \n",
    "    print(add_spaces(text))\n",
    "    print(\"\\n\\n -------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638a816",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion \n",
    "\n",
    "Outcomes: \n",
    "\n",
    "```\n",
    ">>>>>> Temp: 1.0 \n",
    "\n",
    "I am running away. I am \n",
    " running away, \n",
    " and !!!  I am still a long time away. \n",
    "\n",
    "I am not the only one who is looking for me. \n",
    "\n",
    "                   He cried and asked “Why?”“What did you do?”\n",
    "\n",
    "and “Oh my, my sweet  bird.” but to say it is a lie.\n",
    "\n",
    "“Now,” I            said, “I can save my life,  \n",
    " by going.”\n",
    " \n",
    " -------------------------------------\n",
    ">>>>>> Temp: 2.0 \n",
    "\n",
    " \n",
    " I am \n",
    " running away. \n",
    " I am running away,  \n",
    "\t\t\t\t\tHe knows of the boy. \n",
    "\n",
    "“You can find          all here \n",
    "\t by walking“\n",
    "\n",
    "So on his \n",
    " way into an ambush...not just for his \n",
    " escape- but now more.quite close at arm in arm but a little bird \n",
    " \t\tby arm by foot in foot \n",
    "\t\t\t\t\t\ton fire.\n",
    "\n",
    " -------------------------------------\n",
    ">>>>>> Temp: 2.0, Top-K: 100 \n",
    "\n",
    " I am running away. I am running away, and \n",
    "then their mouth must \n",
    "have drifted off: tickling in amazement, his mouth open saying            \n",
    "\t\t\t\t\t\t\t\tso slowly\n",
    " the moment he arrived on that trail; \n",
    "\n",
    "in one short moment\n",
    "had she been frightened now? Oh.\n",
    "\t”Oh dear”, he            \n",
    "\t\t could always think\n",
    "\n",
    "But there were other visitors there.\n",
    "\n",
    "-------------------------------------\n",
    ">>>>>> Temp: 2.0, Top-K: 500 \n",
    "\n",
    "I am running away. I am \n",
    " running away, and ~~ o of, \n",
    "\n",
    "first for whereletfor to kiss\n",
    "now --suddenly and they shall pass by under his power\n",
    "baring him;gone\n",
    "\n",
    "upon her leaves besidegably my side; what remain amoved this parting of story at its length\n",
    "\n",
    "but afterwards ?             all feeling grief slowlyonme\n",
    "\n",
    "broke easily \n",
    " \t\tquiet \n",
    "\n",
    " ```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fe65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
